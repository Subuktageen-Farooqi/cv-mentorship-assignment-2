Terminal run
Installing Pytorch CUda wheel & other libraries
(.venv) PS C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code> pip install --no-cache-dir --index-url https://download.pytorch.org/whl/cu121 `
>>   torch==2.5.1+cu121 torchvision==0.20.1+cu121 torchaudio==2.5.1+cu121
>>
Looking in indexes: https://download.pytorch.org/whl/cu121
Collecting torch==2.5.1+cu121
  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp310-cp310-win_amd64.whl (2449.4 MB)
     ---------------------------------------- 2.4/2.4 GB 4.7 MB/s  0:09:38
Collecting torchvision==0.20.1+cu121
  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp310-cp310-win_amd64.whl (6.1 MB)
     ---------------------------------------- 6.1/6.1 MB 4.8 MB/s  0:00:01
Collecting torchaudio==2.5.1+cu121
  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp310-cp310-win_amd64.whl (4.1 MB)
     ---------------------------------------- 4.1/4.1 MB 6.9 MB/s  0:00:00
Collecting filelock (from torch==2.5.1+cu121)
  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)
Collecting typing-extensions>=4.8.0 (from torch==2.5.1+cu121)
  Downloading https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)
Collecting networkx (from torch==2.5.1+cu121)
  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)
Collecting jinja2 (from torch==2.5.1+cu121)
  Downloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)
Collecting fsspec (from torch==2.5.1+cu121)
  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)
Collecting sympy==1.13.1 (from torch==2.5.1+cu121)
  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)
Collecting numpy (from torchvision==0.20.1+cu121)
  Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)
Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.20.1+cu121)
  Downloading pillow-12.0.0-cp310-cp310-win_amd64.whl.metadata (9.0 kB)
Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.5.1+cu121)
  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)
Collecting MarkupSafe>=2.0 (from jinja2->torch==2.5.1+cu121)
  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp310-cp310-win_amd64.whl (17 kB)
Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)
   ---------------------------------------- 6.2/6.2 MB 1.9 MB/s  0:00:03
Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)
   ---------------------------------------- 536.2/536.2 kB 2.5 MB/s  0:00:00
Downloading pillow-12.0.0-cp310-cp310-win_amd64.whl (7.0 MB)
   ---------------------------------------- 7.0/7.0 MB 2.5 MB/s  0:00:02
Downloading https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl (44 kB)
Downloading filelock-3.20.0-py3-none-any.whl (16 kB)
Downloading fsspec-2025.12.0-py3-none-any.whl (201 kB)
Downloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)
Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)
   ---------------------------------------- 1.7/1.7 MB 3.2 MB/s  0:00:00
Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)
   ---------------------------------------- 12.9/12.9 MB 2.8 MB/s  0:00:04
Installing collected packages: mpmath, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, torchvision, torchaudio
Successfully installed MarkupSafe-2.1.5 filelock-3.20.0 fsspec-2025.12.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 pillow-12.0.0 sympy-1.13.1 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121 typing-extensions-4.15.0
(.venv) PS C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code> python -c "import torch; print(torch.__version__); print(torch.version.cuda); print(torch.cuda.is_available())"
>>
2.5.1+cu121
12.1
True
(.venv) PS C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code> pip install timm onnx onnxruntime onnxruntime-tools pandas scikit-learn matplotlib tqdm
>>
Collecting timm
  Downloading timm-1.0.24-py3-none-any.whl.metadata (38 kB)
Collecting onnx
  Downloading onnx-1.20.1-cp310-cp310-win_amd64.whl.metadata (8.6 kB)
Collecting onnxruntime
  Downloading onnxruntime-1.23.2-cp310-cp310-win_amd64.whl.metadata (5.3 kB)
Collecting onnxruntime-tools
  Downloading onnxruntime_tools-1.7.0-py3-none-any.whl.metadata (14 kB)
Collecting pandas
  Downloading pandas-2.3.3-cp310-cp310-win_amd64.whl.metadata (19 kB)
Collecting scikit-learn
  Downloading scikit_learn-1.7.2-cp310-cp310-win_amd64.whl.metadata (11 kB)
Collecting matplotlib
  Downloading matplotlib-3.10.8-cp310-cp310-win_amd64.whl.metadata (52 kB)
Collecting tqdm
  Downloading tqdm-4.67.3-py3-none-any.whl.metadata (57 kB)
Requirement already satisfied: torch in .\.venv\lib\site-packages (from timm) (2.5.1+cu121)
Requirement already satisfied: torchvision in .\.venv\lib\site-packages (from timm) (0.20.1+cu121)
Collecting pyyaml (from timm)
  Downloading pyyaml-6.0.3-cp310-cp310-win_amd64.whl.metadata (2.4 kB)
Collecting huggingface_hub (from timm)
  Downloading huggingface_hub-1.4.1-py3-none-any.whl.metadata (13 kB)
Collecting safetensors (from timm)
  Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)
Requirement already satisfied: numpy>=1.23.2 in .\.venv\lib\site-packages (from onnx) (2.2.6)
Collecting protobuf>=4.25.1 (from onnx)
  Downloading protobuf-6.33.5-cp310-abi3-win_amd64.whl.metadata (593 bytes)
Requirement already satisfied: typing_extensions>=4.7.1 in .\.venv\lib\site-packages (from onnx) (4.15.0)
Collecting ml_dtypes>=0.5.0 (from onnx)
  Downloading ml_dtypes-0.5.4-cp310-cp310-win_amd64.whl.metadata (9.2 kB)
Collecting coloredlogs (from onnxruntime)
  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)
Collecting flatbuffers (from onnxruntime)
  Downloading flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)
Requirement already satisfied: packaging in .\.venv\lib\site-packages (from onnxruntime) (26.0)
Requirement already satisfied: sympy in .\.venv\lib\site-packages (from onnxruntime) (1.13.1)
Collecting psutil (from onnxruntime-tools)
  Downloading psutil-7.2.2-cp37-abi3-win_amd64.whl.metadata (22 kB)
Collecting py-cpuinfo (from onnxruntime-tools)
  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)
Collecting py3nvml (from onnxruntime-tools)
  Downloading py3nvml-0.2.7-py3-none-any.whl.metadata (13 kB)
Collecting python-dateutil>=2.8.2 (from pandas)
  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)
Collecting pytz>=2020.1 (from pandas)
  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)
Collecting tzdata>=2022.7 (from pandas)
  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)
Collecting scipy>=1.8.0 (from scikit-learn)
  Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl.metadata (60 kB)
Collecting joblib>=1.2.0 (from scikit-learn)
  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)
Collecting threadpoolctl>=3.1.0 (from scikit-learn)
  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)
Collecting contourpy>=1.0.1 (from matplotlib)
  Downloading contourpy-1.3.2-cp310-cp310-win_amd64.whl.metadata (5.5 kB)
Collecting cycler>=0.10 (from matplotlib)
  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)
Collecting fonttools>=4.22.0 (from matplotlib)
  Downloading fonttools-4.61.1-cp310-cp310-win_amd64.whl.metadata (116 kB)
Collecting kiwisolver>=1.3.1 (from matplotlib)
  Downloading kiwisolver-1.4.9-cp310-cp310-win_amd64.whl.metadata (6.4 kB)
Requirement already satisfied: pillow>=8 in .\.venv\lib\site-packages (from matplotlib) (12.0.0)
Collecting pyparsing>=3 (from matplotlib)
  Downloading pyparsing-3.3.2-py3-none-any.whl.metadata (5.8 kB)
Collecting colorama (from tqdm)
  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)
Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas)
  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)
  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)
Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime)
  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)
Requirement already satisfied: filelock in .\.venv\lib\site-packages (from huggingface_hub->timm) (3.20.0)
Requirement already satisfied: fsspec>=2023.5.0 in .\.venv\lib\site-packages (from huggingface_hub->timm) (2025.12.0)
Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface_hub->timm)
  Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl.metadata (5.0 kB)
Collecting httpx<1,>=0.23.0 (from huggingface_hub->timm)
  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)
Collecting shellingham (from huggingface_hub->timm)
  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)
Collecting typer-slim (from huggingface_hub->timm)
  Downloading typer_slim-0.21.1-py3-none-any.whl.metadata (16 kB)
Collecting anyio (from httpx<1,>=0.23.0->huggingface_hub->timm)
  Downloading anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)
Collecting certifi (from httpx<1,>=0.23.0->huggingface_hub->timm)
  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)
Collecting httpcore==1.* (from httpx<1,>=0.23.0->huggingface_hub->timm)
  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)
Collecting idna (from httpx<1,>=0.23.0->huggingface_hub->timm)
  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)
Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub->timm)
  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)
Collecting exceptiongroup>=1.0.2 (from anyio->httpx<1,>=0.23.0->huggingface_hub->timm)
  Downloading exceptiongroup-1.3.1-py3-none-any.whl.metadata (6.7 kB)
Collecting xmltodict (from py3nvml->onnxruntime-tools)
  Downloading xmltodict-1.0.2-py3-none-any.whl.metadata (15 kB)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in .\.venv\lib\site-packages (from sympy->onnxruntime) (1.3.0)
Requirement already satisfied: networkx in .\.venv\lib\site-packages (from torch->timm) (3.4.2)
Requirement already satisfied: jinja2 in .\.venv\lib\site-packages (from torch->timm) (3.1.6)
Requirement already satisfied: MarkupSafe>=2.0 in .\.venv\lib\site-packages (from jinja2->torch->timm) (2.1.5)
Collecting click>=8.0.0 (from typer-slim->huggingface_hub->timm)
  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)
Downloading timm-1.0.24-py3-none-any.whl (2.6 MB)
   ---------------------------------------- 2.6/2.6 MB 5.9 MB/s  0:00:00
Downloading onnx-1.20.1-cp310-cp310-win_amd64.whl (16.4 MB)
   ---------------------------------------- 16.4/16.4 MB 4.3 MB/s  0:00:03
Downloading onnxruntime-1.23.2-cp310-cp310-win_amd64.whl (13.5 MB)
   ---------------------------------------- 13.5/13.5 MB 2.4 MB/s  0:00:05
Downloading onnxruntime_tools-1.7.0-py3-none-any.whl (212 kB)
Downloading pandas-2.3.3-cp310-cp310-win_amd64.whl (11.3 MB)
   ---------------------------------------- 11.3/11.3 MB 993.5 kB/s  0:00:11
Downloading scikit_learn-1.7.2-cp310-cp310-win_amd64.whl (8.9 MB)
   ---------------------------------------- 8.9/8.9 MB 866.6 kB/s  0:00:10
Downloading matplotlib-3.10.8-cp310-cp310-win_amd64.whl (8.1 MB)
   ---------------------------------------- 8.1/8.1 MB 1.8 MB/s  0:00:04
Downloading tqdm-4.67.3-py3-none-any.whl (78 kB)
Downloading contourpy-1.3.2-cp310-cp310-win_amd64.whl (221 kB)
Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)
Downloading fonttools-4.61.1-cp310-cp310-win_amd64.whl (1.6 MB)
   ---------------------------------------- 1.6/1.6 MB 3.6 MB/s  0:00:00
Downloading joblib-1.5.3-py3-none-any.whl (309 kB)
Downloading kiwisolver-1.4.9-cp310-cp310-win_amd64.whl (73 kB)
Downloading ml_dtypes-0.5.4-cp310-cp310-win_amd64.whl (210 kB)
Downloading protobuf-6.33.5-cp310-abi3-win_amd64.whl (437 kB)
Downloading pyparsing-3.3.2-py3-none-any.whl (122 kB)
Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)
Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)
Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)
   ---------------------------------------- 41.3/41.3 MB 3.0 MB/s  0:00:13
Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)
Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)
Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)
Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)
Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)
Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)
Downloading flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)
Downloading huggingface_hub-1.4.1-py3-none-any.whl (553 kB)
   ---------------------------------------- 553.3/553.3 kB 3.1 MB/s  0:00:00
Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl (2.9 MB)
   ---------------------------------------- 2.9/2.9 MB 4.0 MB/s  0:00:00
Downloading httpx-0.28.1-py3-none-any.whl (73 kB)
Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)
Downloading h11-0.16.0-py3-none-any.whl (37 kB)
Downloading pyyaml-6.0.3-cp310-cp310-win_amd64.whl (158 kB)
Downloading anyio-4.12.1-py3-none-any.whl (113 kB)
Downloading exceptiongroup-1.3.1-py3-none-any.whl (16 kB)
Downloading idna-3.11-py3-none-any.whl (71 kB)
Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)
Downloading psutil-7.2.2-cp37-abi3-win_amd64.whl (137 kB)
Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)
Downloading py3nvml-0.2.7-py3-none-any.whl (55 kB)
Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)
Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)
Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)
Downloading typer_slim-0.21.1-py3-none-any.whl (47 kB)
Downloading click-8.3.1-py3-none-any.whl (108 kB)
Downloading xmltodict-1.0.2-py3-none-any.whl (13 kB)
Installing collected packages: pytz, py-cpuinfo, flatbuffers, xmltodict, tzdata, threadpoolctl, six, shellingham, scipy, safetensors, pyyaml, pyreadline3, pyparsing, psutil, protobuf, ml_dtypes, kiwisolver, joblib, idna, hf-xet, h11, fonttools, exceptiongroup, cycler, contourpy, colorama, certifi, tqdm, scikit-learn, python-dateutil, py3nvml, onnx, humanfriendly, httpcore, click, anyio, typer-slim, pandas, matplotlib, httpx, coloredlogs, onnxruntime-tools, onnxruntime, huggingface_hub, timm
Successfully installed anyio-4.12.1 certifi-2026.1.4 click-8.3.1 colorama-0.4.6 coloredlogs-15.0.1 contourpy-1.3.2 cycler-0.12.1 exceptiongroup-1.3.1 flatbuffers-25.12.19 fonttools-4.61.1 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface_hub-1.4.1 humanfriendly-10.0 idna-3.11 joblib-1.5.3 kiwisolver-1.4.9 matplotlib-3.10.8 ml_dtypes-0.5.4 onnx-1.20.1 onnxruntime-1.23.2 onnxruntime-tools-1.7.0 pandas-2.3.3 protobuf-6.33.5 psutil-7.2.2 py-cpuinfo-9.0.0 py3nvml-0.2.7 pyparsing-3.3.2 pyreadline3-3.5.4 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.3 safetensors-0.7.0 scikit-learn-1.7.2 scipy-1.15.3 shellingham-1.5.4 six-1.17.0 threadpoolctl-3.6.0 timm-1.0.24 tqdm-4.67.3 typer-slim-0.21.1 tzdata-2025.3 xmltodict-1.0.2

Checking for GPU
(.venv) PS C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code> python -c "import torch; print(torch.cuda.get_device_name(0)); x=torch.randn(1024,1024,device='cuda'); print(x@x.T)"
>>
NVIDIA GeForce RTX 4060 Laptop GPU
tensor([[1111.6938,    7.8606,   18.7987,  ...,  -10.8720,   49.4843,
           -8.0431],
        [   7.8606, 1028.7291,  -75.8335,  ...,    4.1952,    4.2890,
           32.0095],
        [  18.7987,  -75.8335,  975.8752,  ...,    2.2109,    7.4779,
           37.5039],
        ...,
        [ -10.8720,    4.1952,    2.2109,  ..., 1003.2219,  -37.9818,
           22.9657],
        [  49.4843,    4.2890,    7.4779,  ...,  -37.9818, 1099.2531,
          -19.5058],
        [  -8.0431,   32.0095,   37.5039,  ...,   22.9657,  -19.5058,
         1047.0157]], device='cuda:0')

Training - convnext model
(.venv) PS C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code> python train.py --arch convnext_tiny --dataset cifar10 --epochs 3 --use_amp 1
>> python eval.py --ckpt checkpoints/best_convnext_tiny_cifar10.pt
Files already downloaded and verified
C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code\train.py:132: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler(enabled=use_amp)
train:   0%|                                                                | 0/352 [00:00<?, ?it/s]C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code\train.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
ep 01 | train 0.2220/0.9295 | val 0.1357/0.9526
ep 02 | train 0.0558/0.9822 | val 0.1110/0.9640
ep 03 | train 0.0127/0.9967 | val 0.0710/0.9776
Best val acc: 0.9776
Saved: checkpoints\best_convnext_tiny_cifar10.pt
C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code\eval.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(args.ckpt, map_location="cpu")
Files already downloaded and verified
Saved confusion matrix: part_1_results\cn_convnext_tiny_cifar10.png
Updated summary: part_1_results\summary.txt


Training - TinyCNN model
(.venv) PS C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code> python train.py --arch tinycnn --dataset cifar10 --epochs 1 --img_size 128 --batch_size 256 --use_amp 1
>> python eval.py  --ckpt checkpoints/best_tinycnn_cifar10.pt
>>
Files already downloaded and verified
C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code\train.py:132: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler(enabled=use_amp)
train:   0%|                                                                                                                                                                              | 0/176 [00:00<?, ?it/s]C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code\train.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
ep 01 | train 2.0912/0.2240 | val 2.0009/0.2634
Best val acc: 0.2634
Saved: checkpoints\best_tinycnn_cifar10.pt
C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code\eval.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(args.ckpt, map_location="cpu")
Files already downloaded and verified
Saved confusion matrix: part_1_results\cn_tinycnn_cifar10.png
Updated summary: part_1_results\summary.txt



Training - ViT model
(.venv) PS C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code> python train.py --arch vit_b_16 --dataset cifar10 --epochs 1 --img_size 224 --batch_size 64 --use_amp 1 --freeze_backbone 1
>> python eval.py  --ckpt checkpoints/best_vit_b_16_cifar10.pt
>>
Files already downloaded and verified
Downloading: "https://download.pytorch.org/models/vit_b_16-c867db91.pth" to C:\Users\mumer/.cache\torch\hub\checkpoints\vit_b_16-c867db91.pth
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 330M/330M [01:22<00:00, 4.21MB/s]
C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code\train.py:132: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler(enabled=use_amp)
train:   0%|                                                                                                                                                                              | 0/704 [00:00<?, ?it/s]C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code\train.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
ep 01 | train 0.3849/0.9117 | val 0.1994/0.9422
Best val acc: 0.9422
Saved: checkpoints\best_vit_b_16_cifar10.pt
C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code\eval.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(args.ckpt, map_location="cpu")
Files already downloaded and verified
Saved confusion matrix: part_1_results\cn_vit_b_16_cifar10.png
Updated summary: part_1_results\summary.txt



Export ONNX - Best convnext_tiny_cifar10
.venv) PS C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code> python export_onnx.py --ckpt checkpoints/best_convnext_tiny_cifar10.pt --out part_2_results/model_fp32.onnx
>>
C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code\export_onnx.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(args.ckpt, map_location="cpu")
Exported ONNX: part_2_results/model_fp32.onnx



Quantize Dynamic & static
(.venv) PS C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code> python quantize.py --fp32_onnx part_2_results/model_fp32.onnx --out part_2_results/model_int8_dynamic.onnx --mode dynamic
>>
WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md
Saved dynamic INT8: part_2_results/model_int8_dynamic.onnx

(.venv) PS C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code> # Preprocess ONNX (your ConvNeXt FP32)
>> python -m onnxruntime.quantization.preprocess `
>>   --input part_2_results/model_fp32.onnx `
>>   --output part_2_results/model_fp32_infer.onnx

(.venv) PS C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code> python quantize.py `
>>   --fp32_onnx part_2_results/model_fp32_infer.onnx `
>>   --out part_2_results/model_int8_static.onnx `
>>   --mode static `
>>   --dataset cifar10 `
>>   --img_size 224 `
>>   --calib_batches 3
Files already downloaded and verified
Calib batch 1/3
Calib batch 2/3
Calib batch 3/3
Saved static INT8: part_2_results/model_int8_static.onnx


Eval Onnx - 
(.venv) PS C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code> python eval_onnx.py --onnx part_2_results/model_fp32.onnx --dataset cifar10 --img_size 224
Files already downloaded and verified
Accuracy: 0.9970
Macro F1: 0.9970
Weighted F1: 0.9970

(.venv) PS C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code> Remove-Item part_2_results\model_int8_dynamic.onnx -Force
(.venv) PS C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code> python quantize.py `
>>   --fp32_onnx part_2_results/model_fp32_infer.onnx `
>>   --out part_2_results/model_int8_dynamic.onnx `
>>   --mode dynamic
Saved dynamic INT8: part_2_results/model_int8_dynamic.onnx
(.venv) PS C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code> python eval_onnx.py --onnx part_2_results/model_int8_dynamic.onnx --dataset cifar10 --img_size 224
>>
Files already downloaded and verified
Accuracy: 0.9970
Macro F1: 0.9970
Weighted F1: 0.9970

(.venv) PS C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code> python eval_onnx.py --onnx part_2_results/model_int8_static.onnx --dataset cifar10 --img_size 224
Files already downloaded and verified
Accuracy: 0.9966
Macro F1: 0.9966
Weighted F1: 0.9966
(.venv) PS C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code>

Installing Git
(.venv) PS C:\Users\mumer\OneDrive\Desktop\Subuktageen CV Code> winget install --id Git.Git -e
The `msstore` source requires that you view the following agreements before using.
Terms of Transaction: https://aka.ms/microsoft-store-terms-of-transaction
The source requires the current machine's 2-letter geographic region to be sent to the backend service to function properly (ex. "US").

Do you agree to all the source agreements terms?
[Y] Yes  [N] No: Y
Found Git [Git.Git] Version 2.53.0
This application is licensed to you by its owner.
Microsoft is not responsible for, nor does it grant any licenses to, third-party packages.
Downloading https://github.com/git-for-windows/git/releases/download/v2.53.0.windows.1/Git-2.53.0-64-bit.exe
  ██████████████████████████████  61.5 MB / 61.5 MB
Successfully verified installer hash
Starting package install...
Successfully installed

